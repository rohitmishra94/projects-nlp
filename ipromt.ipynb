{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad3aa73-9a2b-4a76-990e-f38d19e50f45",
   "metadata": {},
   "source": [
    "## Clone the HF transformers repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7da643d-a8d6-4912-b917-8e2a7625b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/huggingface/transformers.git "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f48820-fa02-4145-9df6-ae9e0cb060aa",
   "metadata": {},
   "source": [
    "## download the pretrained model checkpoint and unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b09e263-fd7f-4ffb-9b84-6282ed5fb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/megatron_lm_345m/versions/v0.0/zip -O megatron_lm_345m_v0.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f99f5a2-1057-4a09-8ff1-812414f6d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip megatron_lm_345m_v0.0.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f51453-1eeb-4f12-88db-c99ca015ad73",
   "metadata": {},
   "source": [
    "## convert the checkpoints to load transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6594ce18-e4b3-4bbd-b4fc-42752405303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py release/mp_rank_00/model_optim_rng.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2f19b-2e0e-41b2-bfa4-caa50eaf77cd",
   "metadata": {},
   "source": [
    "## load the tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78f92721-eb93-4444-9d24-67738c5e36fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "# The tokenizer. Megatron was trained with standard tokenizer(s).\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('release/mp_rank_00/')\n",
    "# The path to the config/checkpoint (see the conversion step above).\n",
    "#irectory = os.path.join('releaserank_00')\n",
    "# Load the model from $MYDIR/nvidia/megatron-gpt2-345m.\n",
    "model = GPT2LMHeadModel.from_pretrained('release/mp_rank_00/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6673c8-59e3-44c0-872f-81d7ec9133e8",
   "metadata": {},
   "source": [
    "## Generate the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7559d25-5270-4816-b299-298e4d616ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why are rockets and boosters painted white?\n",
      "\n",
      "The answer is that the rockets and boosters are painted white because they are the only way to get the rocket to the launch pad.\n",
      "\n",
      "The rocket is not a rocket. It is a missile.\n"
     ]
    }
   ],
   "source": [
    "# Generate the sentence.\n",
    "inputs = tokenizer(\"Why are rockets and boosters painted white?\", return_tensors=\"pt\")\n",
    "output = model.generate(input_ids=inputs['input_ids'], max_length=50, num_return_sequences=1)\n",
    "# Output the text.\n",
    "for sentence in output:\n",
    "    sentence = sentence.tolist()\n",
    "    text = tokenizer.decode(sentence, clean_up_tokenization_spaces=True)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059bf2d-bb71-4476-90b8-910aa32142ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
